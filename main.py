from pathlib import Path
import sys

ROOT = Path().cwd().resolve()
BASE_DIR = ROOT
MODELS_DIR   = BASE_DIR / 'models'
sys.path.append(str(MODELS_DIR))
sys.path.append(str(BASE_DIR))


# =============================================================================
# ðŸš€ Notebook principal de experimentaciÃ³n con TensorFlow/Keras
# =============================================================================

experiments = ["< EXP >"]  # Lista de experimentos a ejecutar
for experiment_name in experiments:
  # 1) Definir experimento
  #    El nombre debe coincidir con un archivo YAML en configs/experiments/
  exp_name = experiment_name

  # 2) Cargar configuraciÃ³n
  from utils.experiment.functions import load_config, load_experiment
  cfg = load_config(exp_name)
    
  # 3) Â¿Single-split o K-Fold? | Repeticiones
  k = cfg["dataset"].get("k_folds")
  repeats = cfg["experiment"].get("repeats")

  for rep in range(repeats):

    if k is None or k <= 1:

        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 3A) Flujo Ãºnico â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

        #  3A.1) Cargar experimento
        cfg, NNClass, params, dataset, train_data, val_data, test_idx = \
            load_experiment(exp_name, repeat_index=rep)

        #  3A.1.1) Revisar que 'rep' actual no haya sido previamente ejecutado
        #   Si ya existe classification_report.json  â†’ SALTAR
        rep_report = BASE_DIR / cfg['experiment']['output_root'] / cfg['experiment']['output_subdir'] / "reports" / "classification_report.json"
        if rep_report.exists() == True:
          print(f"[SKIP] Rep: {rep} (singleâ€split) â†’ ya existe classification_report.json.")
          continue

        #  3A.2) Instanciar y Entrenar
        model   = NNClass(cfg, **params)

        if rep == 0:
          #  3A.3 ) Mostrar resumen de la configuraciÃ³n
          from utils.misc.functions import print_exp_configuration
          print(f"\nâœ”ï¸ Experimento Â«{cfg['experiment']['name']}Â» cargado con Ã©xito.\n")
          print_exp_configuration(cfg)

          #  3A.4) Mostrar arquitectura del modelo
          print("\nðŸ“‹ Arquitectura del modelo:")
          model.model.summary()

        print("\n"*5)
        print(f"\nðŸ”„ Rep {rep+1}/{repeats}")
        #  4A.5) Entrenamiento (o retomar desde Ãºltimo checkpoint)
        history = model.fit(train_data, val_data)

        #  4A.6) AnÃ¡lisis resultados individual
        from utils.analysis.analysis import ExperimentAnalyzer
        analyzer = ExperimentAnalyzer(
              model=model.model,
              history=history,
              test_data=test_idx,
              cfg=cfg,
              effects=dataset.get_effects("test"),
              repeat_index=rep,
              show_plots=False,
          )

        analyzer.classification_report()
        analyzer.effect_report()
        analyzer.confusion_matrix(normalize="true")
        model.cleanup_old_checkpoints()

    else:
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 3B) Flujo K-Fold â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        if rep == 0:
          #  3B.1) Cargar experimento con primer FOLD INDEX (fines informativos en consola)
          cfg, NNClass, params, _, _, _, _ = load_experiment(exp_name, fold_index=0, repeat_index=0)

          #  3B.2) Instanciar para obtener modelo y poder imprimir parÃ¡metros
          model   = NNClass(cfg, **params)

          #  3B.3 ) Mostrar resumen de la configuraciÃ³n
          from utils.misc.functions import print_exp_configuration
          print(f"\nâœ”ï¸ Experimento Â«{cfg['experiment']['name']}Â» cargado con Ã©xito.\n")
          print_exp_configuration(cfg)

          #  3B.4) Mostrar arquitectura del modelo
          print("\nðŸ“‹ Arquitectura del modelo:")
          model.model.summary()

        #  3B.5) K-FOLD
        for fold in range(k):
            print("\n"*5)
            print(f"\nðŸ”„ Rep {rep+1}/{repeats} | Fold {fold+1}/{k}")

            #  3B.5.1) Cargar experimento
            cfg, NNClass, params, dataset, train_data, val_data, test_idx = \
                load_experiment(exp_name, repeat_index=rep, fold_index=fold)

            #  3B.5.2) Revisar que 'rep' y 'fold' actual no hayan sido previamente ejecutados
            #   Si ya existe: /reports/classification_report.json  â†’ SALTAR
            rep_report = BASE_DIR / cfg['experiment']['output_root'] / cfg['experiment']['output_subdir'] / "reports" / "classification_report.json"
            if rep_report.exists() == True:
              print(f"[SKIP] Rep: {rep} Fold: {fold}  â†’ ya existe classification_report.json.")
              continue

            #  3B.5.4) Instanciar y Entrenar
            model   = NNClass(cfg, **params)
            history = model.fit(train_data, val_data)

            #  3B.5.4) AnÃ¡lisis resultados individual
            from utils.analysis.analysis import ExperimentAnalyzer
            analyzer = ExperimentAnalyzer(
                model=model.model,
                history=history,
                test_data=test_idx,
                cfg=cfg,
                repeat_index=rep,
                fold_index=fold,
                effects=dataset.get_effects("test"),
                show_plots=False,
            )

            # Guardar mÃ©tricas en JSON
            analyzer.classification_report()
            analyzer.effect_report()
            analyzer.confusion_matrix(normalize="true")
            model.cleanup_old_checkpoints()

  print("\n"*4)
  print("="*15, f" | PROCESO {exp_name} FINALIZADO CORRECTAMENTE | ", "="*15)
  print("\n"*4)

# 4) AnÃ¡lisis Final
# from utils.analysis.analysis_rep import ExperimentRepAnalyzer
# analyzer = ExperimentRepAnalyzer(
#     cfg=load_config(exp_name)
# )

# analyzer.report_summary(confidence=0.95) # Resumen de mÃ©tricas por repeticiÃ³n y fold
# analyzer.plot_evaluation(confidence=0.95) # GrÃ¡fica de evaluaciÃ³n (loss/accuracy con IC)

# analyzer.show_dashboard(confidence=0.95) # Dahsboard con todas las grÃ¡ficas


# print("\n"*4)
# print("="*15, " | PROCESO FINALIZADO CORRECTAMENTE | ", "="*15)
# print("\n"*4)
